{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grKZ7Xesyjm0"
   },
   "source": [
    "<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/banner_IA.png\"  width=\"1000px\" height=\"200px\">\n",
    "\n",
    "# **Taller 03:  Pandas**\n",
    "\n",
    "## **Outline**\n",
    "\n",
    "1. [Ejercicio 1.](#eje1)\n",
    "2. [Ejercicio 2.](#eje2)\n",
    "3. [Ejercicio 3.](#eje3)\n",
    "4. [Ejercicio 4.](#eje4)\n",
    "5. [Ejercicio 5.](#eje5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1757515606656,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "Ic9xabc8Hvy2",
    "outputId": "8b032121-0876-43fb-d457-ae74ad5cc2d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPut your student ID here\\n\\nExample: student_id =  '2152145'\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title **Execute this cell**\n",
    "#@markdown Please include your student id\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "group_id = \"IA1-20252-G1\" #@param {type:\"string\"}\n",
    "assignment_id = group_id +'.taller_pandas'\n",
    "student_id = \"2225112\" #@param {type:\"string\"}\n",
    "\"\"\"\n",
    "Put your student ID here\n",
    "\n",
    "Example: student_id =  '2152145'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1757515653555,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "HoNtDObzy4d-"
   },
   "outputs": [],
   "source": [
    " #@title **Execute this cell**\n",
    "#@markdown **UTILS**\n",
    "#@markdown Please dont modify any line in this cell\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "Config = namedtuple('Config', ['server_name'])\n",
    "config = Config(server_name='https://bivlabgrader.azurewebsites.net/api')\n",
    "\n",
    "\n",
    "def check_solution_and_evaluate(assignment_id: str, student_func_str: str):\n",
    "\n",
    "    # Set the endpoint and payload.\n",
    "    payload = {\n",
    "        'func_str': student_func_str,\n",
    "        'assignment_id': assignment_id,\n",
    "        'student_id': student_id\n",
    "    }\n",
    "    endpoint_url = config.server_name + '/CheckAndEvaluateSolution'\n",
    "    # print(endpoint_url)\n",
    "\n",
    "    # Make request to server with the data coming from the notebook.\n",
    "    r = requests.post(endpoint_url, params=payload)\n",
    "    pprint_json_response(r.json())\n",
    "    return r\n",
    "\n",
    "\n",
    "def pprint_json_response(response, indent=0):\n",
    "    \"\"\"Pretty print the response.\"\"\"\n",
    "    for key, value in response.items():\n",
    "        print('\\t' * indent + str(key.capitalize()))\n",
    "\n",
    "        # If dictionary, do a recurrent call.\n",
    "        if isinstance(value, dict):\n",
    "            pprint_json_response(value, indent + 1)\n",
    "        else:\n",
    "            # Enumerate elements if list.\n",
    "            if isinstance(value, list):\n",
    "                if len(value) == 1:\n",
    "                    print('\\t' * (indent + 1) + str(value[0]))\n",
    "                else:\n",
    "                    for i, e in enumerate(value, start=1):\n",
    "                        print('\\t' * (indent + 1) + f'{i}. {e}')\n",
    "            else:\n",
    "                print('\\t' * (indent + 1) + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1757515656026,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "aEJwAMtC0KOp"
   },
   "outputs": [],
   "source": [
    "#@title **Import libraries**\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_6ht_FU3Ycj"
   },
   "source": [
    "---\n",
    "# **Ejercicio 1**  <a name=\"eje1\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2thz25v3b68"
   },
   "source": [
    "#  Imputación condicional de valores faltantes\n",
    "\n",
    "## Contexto\n",
    "En un DataFrame con dos columnas:\n",
    "\n",
    "* `value`: variable numérica que puede contener valores faltantes (`NaN`).\n",
    "* `is_normal`: columna booleana que indica la estrategia de imputación para **esa fila**.\n",
    "\n",
    "Debes reemplazar los `NaN` de `value` según:\n",
    "\n",
    "* Si `is_normal == True` → imputar con la **media** de `value` (ignorando `NaN`).\n",
    "* Si `is_normal == False` → imputar con la **mediana** de `value` (ignorando `NaN`).\n",
    "\n",
    "Los valores no faltantes deben permanecer iguales.\n",
    "Si **toda** la columna `value` es `NaN`, tanto la media como la mediana serán `NaN` y, por lo tanto, los faltantes permanecerán como `NaN` (comportamiento esperado).<br><br>\n",
    "\n",
    "## Tu tarea\n",
    "Desarrollar la función `impute_conditional(df)` la cual recibe un dataframe `(df)`, de manera que se cumplan los requerimientos solicitados.<br><br>\n",
    "\n",
    "## Prueba tu solución\n",
    "Se entregan seis (6) posibles casos de uso para poner a prueba su solución.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1757518723988,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "Om0rxBun3Wex"
   },
   "outputs": [],
   "source": [
    "#@title **code student**\n",
    "\n",
    "def impute_conditional(df):\n",
    "    import pandas as pd\n",
    "    from typing import Optional\n",
    "\n",
    "    for i, element in enumerate(df[\"value\"]):\n",
    "        if pd.isna(element):\n",
    "            if df[\"is_normal\"][i] == True:\n",
    "                df[\"value\"][i] = df[\"value\"].mean()\n",
    "            else:\n",
    "                df[\"value\"][i] = df[\"value\"].median()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yCThRZ-QEZc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_21244\\3125117170.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"value\"][i] = df[\"value\"].median()\n"
     ]
    }
   ],
   "source": [
    "#@title **check your answer**\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 1: Ejemplo simple\n",
    "# ---------------------------\n",
    "df1 = pd.DataFrame({\n",
    "    \"value\": [10.0, None, 20.0, None, 30.0],\n",
    "    \"is_normal\": [True, True, False, False, True]\n",
    "})\n",
    "# media = (10 + 20 + 30)/3 = 20.0 ; mediana = 20.0\n",
    "expected1 = pd.DataFrame({\n",
    "    \"value\": [10.0, 20.0, 20.0, 20.0, 30.0],\n",
    "    \"is_normal\": [True, True, False, False, True]\n",
    "})\n",
    "print(impute_conditional(df1).equals(expected1))  # ✅ True si es correcto\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 2: Típico con media ≠ mediana\n",
    "# ---------------------------\n",
    "df2 = pd.DataFrame({\n",
    "    \"value\": [5.0, None, 100.0, None, 7.0, 9.0, None],\n",
    "    \"is_normal\": [True, False, True, False, True, True, False]\n",
    "})\n",
    "# valores no-NaN: [5, 100, 7, 9] -> media = 30.25 ; mediana = (7 + 9)/2 = 8.0\n",
    "expected2 = pd.DataFrame({\n",
    "    \"value\": [\n",
    "        5.0,     # se queda\n",
    "        8.0,     # NaN & is_normal=False -> mediana 8.0\n",
    "        100.0,   # se queda\n",
    "        8.0,     # NaN & is_normal=False -> mediana 8.0\n",
    "        7.0,     # se queda\n",
    "        9.0,     # se queda\n",
    "        8.0      # NaN & is_normal=False -> mediana 8.0\n",
    "    ],\n",
    "    \"is_normal\": [True, False, True, False, True, True, False]\n",
    "})\n",
    "print(impute_conditional(df2).equals(expected2))  # ✅ True si es correcto\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 3: Solo imputación por media (todas las filas True)\n",
    "# ---------------------------\n",
    "df3 = pd.DataFrame({\n",
    "    \"value\": [None, 2.0, None, 8.0],\n",
    "    \"is_normal\": [True, True, True, True]\n",
    "})\n",
    "# media = (2 + 8)/2 = 5.0 ; mediana no se usa\n",
    "expected3 = pd.DataFrame({\n",
    "    \"value\": [5.0, 2.0, 5.0, 8.0],\n",
    "    \"is_normal\": [True, True, True, True]\n",
    "})\n",
    "print(impute_conditional(df3).equals(expected3))  # ✅ True si es correcto\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 4: Solo imputación por mediana (todas las filas False)\n",
    "# ---------------------------\n",
    "df4 = pd.DataFrame({\n",
    "    \"value\": [1.0, None, 9.0, None, 3.0],\n",
    "    \"is_normal\": [False, False, False, False, False]\n",
    "})\n",
    "# valores no-NaN: [1, 9, 3] -> mediana = 3.0\n",
    "expected4 = pd.DataFrame({\n",
    "    \"value\": [1.0, 3.0, 9.0, 3.0, 3.0],\n",
    "    \"is_normal\": [False, False, False, False, False]\n",
    "})\n",
    "print(impute_conditional(df4).equals(expected4))  # ✅ True si es correcto\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 5: Borde - toda la columna value es NaN\n",
    "# ---------------------------\n",
    "df5 = pd.DataFrame({\n",
    "    \"value\": [None, None],\n",
    "    \"is_normal\": [True, False]\n",
    "})\n",
    "# media = NaN ; mediana = NaN -> permanecen NaN\n",
    "expected5 = pd.DataFrame({\n",
    "    \"value\": [None, None],\n",
    "    \"is_normal\": [True, False]\n",
    "})\n",
    "print(impute_conditional(df5).equals(expected5))  # ✅ True si es correcto\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 6: Sin NaN (no debe cambiar nada)\n",
    "# ---------------------------\n",
    "df6 = pd.DataFrame({\n",
    "    \"value\": [2.0, 4.0, 6.0],\n",
    "    \"is_normal\": [True, False, True]\n",
    "})\n",
    "expected6 = df6.copy()\n",
    "print(impute_conditional(df6).equals(expected6))  # ✅ True si es correcto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjngkljNQ6Jy"
   },
   "source": [
    "## ✅ Salidas esperadas\n",
    "\n",
    "```\n",
    "True\n",
    "True\n",
    "True\n",
    "True\n",
    "True\n",
    "True\n",
    "/usr/local/lib/python3.12/dist-packages/numpy/lib/_nanfunctions_impl.py:1231: RuntimeWarning: Mean of empty slice\n",
    "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "27D6EuJ74pw-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "\t5.0\n",
      "Message\n",
      "\tExcellent, you got the highest score.\n",
      "Status\n",
      "\tYou have achieved your best score: 5.0\n"
     ]
    }
   ],
   "source": [
    "#@title **send your answer**\n",
    "student_func_str = inspect.getsource(impute_conditional)\n",
    "r = check_solution_and_evaluate(assignment_id, student_func_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHsQtqUsKhQJ"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xi09XP3ZAiiP"
   },
   "source": [
    "---\n",
    "# **Ejercicio 2**  <a name=\"eje2\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1pqchILAoQv"
   },
   "source": [
    "# Nota final con penalización por entrega tardía\n",
    "\n",
    "## Contexto\n",
    "\n",
    "Trabajarás con un **DataFrame de notas** por asignación y estudiante. Cada fila representa la calificación de un estudiante en una actividad, el **peso** que dicha actividad aporta a la nota final y si la **entrega fue a tiempo**.\n",
    "En este entorno, las entregas **fuera de tiempo** tienen una **penalización del 40%** sobre la nota de esa actividad. Además, los pesos pueden estar expresados como **proporción** (`0..1`) o como **porcentaje** (`0..100`) e incluso venir **mezclados** en la misma columna, por lo que es necesario **normalizarlos** a proporción antes de ponderar.\n",
    "\n",
    "Columnas fijas del DataFrame:\n",
    "\n",
    "* `student_id`: código del estudiante\n",
    "* `assignment`: nombre de la asignación\n",
    "* `final_weight`: peso final de la asignación (proporción `0..1` o porcentaje `0..100`)\n",
    "* `grade`: nota obtenida (0–100)\n",
    "* `on_time`: `True` si entregó a tiempo, `False` si fue tarde\n",
    "\n",
    "## Tu Tarea\n",
    "\n",
    "Implementa **`compute_final_grades(df)`** que devuelva un DataFrame **`summary_df`** con la **nota final por estudiante**, con columnas:\n",
    "\n",
    "   * `student_id`\n",
    "   * `final_grade = Σ weighted_score` de todas sus filas\n",
    "\n",
    "## Ejemplos\n",
    "\n",
    "### Ejemplo 1: Pesos en porcentaje y una entrega tarde\n",
    "\n",
    "**Entrada (fragmento):**\n",
    "\n",
    "```\n",
    "student_id | assignment | final_weight | grade | on_time\n",
    "-----------|------------|--------------|-------|---------\n",
    "A          | T1         | 40           | 80    | True\n",
    "A          | T2         | 60           | 90    | False\n",
    "```\n",
    "\n",
    "**Cálculo:**\n",
    "\n",
    "* `weight_prop`: 40%→0.4, 60%→0.6\n",
    "* `adjusted_grade`: T1=80; T2=90\\*0.60=54\n",
    "* `weighted_score`: T1=80 * 0.4=32; T2=54 * 0.6=32.4\n",
    "* **final\\_grade(A) = 32 + 32.4 = 64.4**\n",
    "\n",
    "### Ejemplo 2: Mezcla de porcentaje y proporción, todo a tiempo\n",
    "\n",
    "**Entrada (fragmento):**\n",
    "\n",
    "```\n",
    "student_id | assignment | final_weight | grade | on_time\n",
    "-----------|------------|--------------|-------|---------\n",
    "B          | P1         | 0.5          | 70    | True\n",
    "B          | P2         | 50           | 100   | True\n",
    "```\n",
    "\n",
    "**Cálculo:**\n",
    "\n",
    "* `weight_prop`: 0.5→0.5, 50%→0.5\n",
    "* `adjusted_grade`: P1=70; P2=100\n",
    "* `weighted_score`: P1=70 * 0.5=35; P2=100 * 0.5=50\n",
    "* **final\\_grade(B) = 35 + 50 = 85**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1757516008213,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "DN2ahWNOEGZ4"
   },
   "outputs": [],
   "source": [
    "#@title **code student**\n",
    "\n",
    "def compute_final_grades(df):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    out[\"weight_prop\"] = np.where(out[\"final_weight\"] > 1,\n",
    "                                 out[\"final_weight\"] / 100,\n",
    "                                 out[\"final_weight\"])\n",
    "    \n",
    "    out[\"adjusted_grade\"] = np.where(out[\"on_time\"],\n",
    "                                    out[\"grade\"],         \n",
    "                                    out[\"grade\"] * 0.6)   \n",
    "    \n",
    "\n",
    "    out[\"weighted_score\"] = out[\"adjusted_grade\"] * out[\"weight_prop\"]\n",
    "\n",
    "    # Nota final por estudiante\n",
    "    summary = (\n",
    "        out.groupby(\"student_id\", as_index=False)[\"weighted_score\"]\n",
    "           .sum()\n",
    "           .rename(columns={\"weighted_score\": \"final_grade\"})\n",
    "    )\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6YK-yxyAEMsA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1 - summary: True\n",
      "Caso 2 - summary: True\n",
      "Caso 3 - summary: True\n",
      "Caso 4 - summary: True\n",
      "Caso 5 - summary: True\n"
     ]
    }
   ],
   "source": [
    "#@title **check your answer**\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def df_equal_float(df1, df2):\n",
    "    \"\"\"Convierte todas las columnas numéricas a float antes de comparar con .equals\"\"\"\n",
    "    df1c = df1.copy()\n",
    "    df2c = df2.copy()\n",
    "    for c in df1c.columns.intersection(df1c.select_dtypes(include=\"number\").columns):\n",
    "        df1c[c] = df1c[c].astype(float)\n",
    "    for c in df2c.columns.intersection(df2c.select_dtypes(include=\"number\").columns):\n",
    "        df2c[c] = df2c[c].astype(float)\n",
    "    return df1c.equals(df2c)\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 1\n",
    "# ---------------------------\n",
    "df1 = pd.DataFrame({\n",
    "    \"student_id\": [\"A\", \"A\", \"B\", \"B\"],\n",
    "    \"assignment\": [\"T1\", \"T2\", \"T1\", \"T2\"],\n",
    "    \"final_weight\": [40, 60, 40, 60],\n",
    "    \"grade\": [80, 90, 70, 100],\n",
    "    \"on_time\": [True, True, False, True]\n",
    "})\n",
    "summary1_expected = pd.DataFrame({\n",
    "    \"student_id\": [\"A\", \"B\"],\n",
    "    \"final_grade\": [86.0, 76.8]\n",
    "})\n",
    "summary1 = compute_final_grades(df1)\n",
    "print(\"Caso 1 - summary:\", df_equal_float(summary1, summary1_expected))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 2\n",
    "# ---------------------------\n",
    "df2 = pd.DataFrame({\n",
    "    \"student_id\": [\"S1\", \"S1\", \"S2\", \"S2\", \"S2\"],\n",
    "    \"assignment\": [\"A1\", \"A2\", \"A1\", \"A2\", \"A3\"],\n",
    "    \"final_weight\": [0.25, 0.75, 0.5, 0.25, 0.25],\n",
    "    \"grade\": [100, 80, 90, 60, 50],\n",
    "    \"on_time\": [True, False, False, False, True]\n",
    "})\n",
    "summary2_expected = pd.DataFrame({\n",
    "    \"student_id\": [\"S1\", \"S2\"],\n",
    "    \"final_grade\": [61.0, 48.5]\n",
    "})\n",
    "summary2 = compute_final_grades(df2)\n",
    "print(\"Caso 2 - summary:\", df_equal_float(summary2, summary2_expected))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 3\n",
    "# ---------------------------\n",
    "df3 = pd.DataFrame({\n",
    "    \"student_id\": [\"X\", \"X\", \"Y\"],\n",
    "    \"assignment\": [\"HW1\", \"HW2\", \"HW1\"],\n",
    "    \"final_weight\": [50, 0.5, 50],\n",
    "    \"grade\": [80, 100, 90],\n",
    "    \"on_time\": [True, False, False]\n",
    "})\n",
    "summary3_expected = pd.DataFrame({\n",
    "    \"student_id\": [\"X\", \"Y\"],\n",
    "    \"final_grade\": [70.0, 27.0]\n",
    "})\n",
    "summary3 = compute_final_grades(df3)\n",
    "print(\"Caso 3 - summary:\", df_equal_float(summary3, summary3_expected))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 4\n",
    "# ---------------------------\n",
    "df4 = pd.DataFrame({\n",
    "    \"student_id\": [\"Z\", \"Z\"],\n",
    "    \"assignment\": [\"Quiz\", \"Proyecto\"],\n",
    "    \"final_weight\": [0, 100],\n",
    "    \"grade\": [0, 80],\n",
    "    \"on_time\": [False, True]\n",
    "})\n",
    "summary4_expected = pd.DataFrame({\n",
    "    \"student_id\": [\"Z\"],\n",
    "    \"final_grade\": [80.0]\n",
    "})\n",
    "summary4 = compute_final_grades(df4)\n",
    "print(\"Caso 4 - summary:\", df_equal_float(summary4, summary4_expected))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Caso 5\n",
    "# ---------------------------\n",
    "df5 = pd.DataFrame({\n",
    "    \"student_id\": [\"U\", \"U\"],\n",
    "    \"assignment\": [\"P1\", \"P2\"],\n",
    "    \"final_weight\": [0.5, 0.5],\n",
    "    \"grade\": [80, 70],\n",
    "    \"on_time\": [False, False]\n",
    "})\n",
    "summary5_expected = pd.DataFrame({\n",
    "    \"student_id\": [\"U\"],\n",
    "    \"final_grade\": [45.0]\n",
    "})\n",
    "summary5 = compute_final_grades(df5)\n",
    "print(\"Caso 5 - summary:\", df_equal_float(summary5, summary5_expected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LegmF57Wuvh"
   },
   "source": [
    "## ✅ Salidas esperadas\n",
    "\n",
    "```\n",
    "Caso 1 - summary: True\n",
    "Caso 2 - summary: True\n",
    "Caso 3 - summary: True\n",
    "Caso 4 - summary: True\n",
    "Caso 5 - summary: True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "R-Mx3FogErMk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "\t5.0\n",
      "Message\n",
      "\tExcellent, you got the highest score.\n",
      "Status\n",
      "\tYou have achieved your best score: 5.0\n"
     ]
    }
   ],
   "source": [
    "#@title **send your answer**\n",
    "student_func_str = inspect.getsource(compute_final_grades)\n",
    "r = check_solution_and_evaluate(assignment_id, student_func_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGNqr2vRKzuY"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPk-vYL30z3H"
   },
   "source": [
    "---\n",
    "# **Ejercicio 3**  <a name=\"eje3\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES7KrNKU0z3I"
   },
   "source": [
    "## Manejo de valores NaN\n",
    "\n",
    "## Contexto\n",
    "\n",
    "En la práctica clínica, la escala Hoehn & Yahr (H&Y) se utiliza con frecuencia para clasificar la progresión de la enfermedad de Parkinson, con valores que van de 0 (sin síntomas) a 5 (discapacidad severa). Dentro de las diferentes tareas motoras analizadas durante la rutina clinica, tareas como el *finger tapping, el grasping y el toe tapping* son fundamentales para calcular la Modified Bradykinesia Rating Scale (MBRS), útil para un análisis cuantitativo del deterioro neurológico. Sin embargo, es común que durante la recolección de datos clínicos haya valores faltantes (NaN) en estas columnas, lo que dificulta los análisis posteriores. Para mantener la coherencia clínica, dichos valores, una estrategia puede ser completarse teniendo en cuenta el estadio H&Y de cada paciente.\n",
    "\n",
    "## Tu tarea\n",
    "\n",
    "Implementar la función `fill_nan`, a la cual ingresa un DataFrame `df` que contiene las siguientes columnas:\n",
    "* `\"H&Y_stage\"` (entero de 0 a 5)\n",
    "* `\"finger_tapping\"` (escala 0–4, puede contener NaN)\n",
    "* `\"grasping\"` (escala 0–4, puede contener NaN)\n",
    "* `\"toe_tapping\"` (escala 0–4, puede contener NaN)\n",
    "\n",
    "Tu misión es completar los valores faltantes (`NaN`) en las tres columnas motoras (``finger_tapping, grasping, toe_tapping``) agrupando por ``\"H&Y_stage\"`` y reemplazando los NaN con el promedio de cada columna dentro del grupo correspondiente.<br><br>Posteriormente, debes <ins>retornar</ins> el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1757516336191,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "w9NRhOuC1_KU"
   },
   "outputs": [],
   "source": [
    "#@title **code student**\n",
    "\n",
    "def fill_nan(df):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    df = df.copy()\n",
    "      \n",
    "    motor_cols = [\"finger_tapping\", \"grasping\", \"toe_tapping\"]\n",
    "    \n",
    "    for col in motor_cols:\n",
    "        group_means = df.groupby(\"H&Y_stage\")[col].transform(\"mean\")\n",
    "        df[col] = df[col].fillna(group_means)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1757516338358,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "P9LCmBx82TgZ",
    "outputId": "a116f7d8-9ee4-4e7a-d361-edff1a768339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   H&Y_stage  finger_tapping  grasping  toe_tapping\n",
      "0          1             1.0       2.0          1.0\n",
      "1          1             1.0       1.0          2.0\n",
      "2          2             2.0       3.0          3.0\n",
      "3          2             3.0       3.0          3.0\n",
      "4          3             4.0       4.0          2.0\n",
      "5          3             4.0       4.0          2.0\n"
     ]
    }
   ],
   "source": [
    "#@title **check your answer**\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "      \"H&Y_stage\": [1, 1, 2, 2, 3, 3],\n",
    "      \"finger_tapping\": [1, np.nan, 2, 3, np.nan, 4],\n",
    "      \"grasping\": [2, 1, np.nan, 3, 4, np.nan],\n",
    "      \"toe_tapping\": [1, 2, 3, np.nan, 2, np.nan]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(fill_nan(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dmpF7-T5H3x"
   },
   "source": [
    "## ✅ Salidas esperadas\n",
    "\n",
    "```\n",
    "   H&Y_stage  finger_tapping  grasping  toe_tapping\n",
    "0          1             1.0       2.0          1.0\n",
    "1          1             1.0       1.0          2.0\n",
    "2          2             2.0       3.0          3.0\n",
    "3          2             3.0       3.0          3.0\n",
    "4          3             4.0       4.0          2.0\n",
    "5          3             4.0       4.0          2.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "m1vRcPBE5WC-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "\t5.0\n",
      "Message\n",
      "\tExcellent, you got the highest score.\n",
      "Status\n",
      "\tYou have achieved your best score: 5.0\n"
     ]
    }
   ],
   "source": [
    "#@title **send your answer**\n",
    "student_func_str = inspect.getsource(fill_nan)\n",
    "r = check_solution_and_evaluate(assignment_id, student_func_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-DRKPtWK4bs"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6Rct60M7MgD"
   },
   "source": [
    "---\n",
    "# **Ejercicio 4**  <a name=\"eje4\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wE_Ec4sU7MgE"
   },
   "source": [
    "## Análisis de visitas clínicas con resample\n",
    "\n",
    "## Contexto\n",
    "Un paciente con enfermedad de Parkinson asiste a consultas de seguimiento donde se registra su puntaje en la escala MBRS (0–12). Sin embargo, las visitas no siempre ocurren con la misma frecuencia: a veces cada semana, otras veces cada varios días. Para analizar la progresión de manera uniforme, es útil reagrupar los datos en intervalos regulares (ejemplo: mensual) y calcular estadísticos en esos intervalos.\n",
    "\n",
    "## Tu tarea\n",
    "\n",
    "Implementar una función `clinical_resample` que recibe como parámetro un dataframe `df` que contiene puntajes MBRS en intervalos mensuales. Para ello deberás:\n",
    "- reagrupar los puntajes MBRS por meses (intervalos mensuales, según la columna `fecha`) utilizando el método `resample(\"ME\")`.\n",
    "- posteriormente, calcule los valores estadísticos `\"mean\", \"min\", \"max\"` que permitan ver la progresión clínica del paciente.\n",
    "- **retorne** el dataframe resultante.\n",
    "\n",
    "<ins>**Nota:**</ins> usted puede calcular dichos valores estadísticos utilizando el método `agg`, el cual permite indicar qué operaciones se desean aplicar a una (o más) columnas. Por ejemplo, si desea aplicar el promedio (`\"mean\"`), el valor mínimo (`\"min\"`) y el valor máximo (`\"max\"`) a una columna llamada (`\"micolumna\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1757517124312,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "65IDCQY77MgE"
   },
   "outputs": [],
   "source": [
    "#@title **code student**\n",
    "\n",
    "def clinical_resample(df):\n",
    "\timport pandas as pd\n",
    "\n",
    "\tdf_resample = df.resample('ME').agg({\"MBRS_score\": [\"mean\", \"min\", \"max\"]})\n",
    "\n",
    "\treturn df_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "x-ZoxYT_7MgE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MBRS_score        \n",
      "                 mean min max\n",
      "fecha                        \n",
      "2023-01-31   5.000000   4   6\n",
      "2023-02-28   6.500000   6   7\n",
      "2023-03-31   8.333333   8   9\n",
      "2023-04-30  10.000000  10  10\n"
     ]
    }
   ],
   "source": [
    "#@title **check your answer**\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"fecha\": [\n",
    "        \"2023-01-05\", \"2023-01-12\", \"2023-01-28\",\n",
    "        \"2023-02-03\", \"2023-02-18\",\n",
    "        \"2023-03-02\", \"2023-03-15\", \"2023-03-30\",\n",
    "        \"2023-04-10\"\n",
    "    ],\n",
    "    \"MBRS_score\": [5, 6, 4, 7, 6, 8, 9, 8, 10]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"fecha\"] = pd.to_datetime(df[\"fecha\"])\n",
    "df = df.set_index(\"fecha\")\n",
    "\n",
    "print(clinical_resample(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQSLghSP7MgE"
   },
   "source": [
    "## ✅ Salidas esperadas\n",
    "\n",
    "```\n",
    "           MBRS_score        \n",
    "                 mean min max\n",
    "fecha                        \n",
    "2023-01-31   5.000000   4   6\n",
    "2023-02-28   6.500000   6   7\n",
    "2023-03-31   8.333333   8   9\n",
    "2023-04-30  10.000000  10  10\n",
    "/tmp/ipython-input-1533716997.py:6: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
    "  df_resample = df.resample(\"M\").agg({\"MBRS_score\": [\"mean\", \"min\", \"max\"]})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GVnHEkGV7MgE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "\t0.0\n",
      "Message\n",
      "\tError ejecutando test 1: Invalid frequency: ME\n"
     ]
    }
   ],
   "source": [
    "#@title **send your answer**\n",
    "student_func_str = inspect.getsource(clinical_resample)\n",
    "r = check_solution_and_evaluate(assignment_id, student_func_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7jwsP1yK85j"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nYFZ52dG71k"
   },
   "source": [
    "---\n",
    "# **Ejercicio 5**  <a name=\"eje5\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aflo4IAVHGp_"
   },
   "source": [
    "# Suavizado de síntomas motores MBRS con rolling\n",
    "\n",
    "## Contexto:\n",
    "\n",
    "Antes de solucionar este punto, por favor **tenga en cuenta** el contexto clinico presentado en [1]:\n",
    "\n",
    "En evaluaciones clínicas seriadas, los puntajes de la MBRS (*Modified Bradykinesia Rating Scale*) pueden presentar fluctuaciones leves entre mediciones sucesivas. Un método común para analizar la tendencia del paciente es aplicar un promedio móvil con ventana definida.\n",
    "\n",
    "## Tu tarea\n",
    "\n",
    "Implementa un la función ``mbrs_rolling``, la cual toma como parámetro un dataframe ``df`` y aplica:\n",
    "- una operación `mean` por el método `rolling` que abarque 3 observaciones sobre la columna (`\"MBRS_score\"`) y <ins>retorne</ins> un dataframe con la señal original (`\"MBRS_score\"`) y su versión suavizada (`\"MBRS_smooth\"`).\n",
    "- una operación `std` por el método `rolling` que abarque 2 observaciones sobre la columna (`\"HYY_score\"`) y <ins>retorne</ins> **solamente** la versión suavizada.\n",
    "- una operación de correlación, con 2 observaciones de longitud, **entre las columnas** (`\"MBRS_score\"`) y (`\"HYY_score\"`), y <ins>retorne</ins> el resultado.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<font size=\"1\">\n",
    "[1] <ins>Contexto clínico:</ins> El diagnóstico clínico de la enfermedad de Parkinson (EP) se basa en la evaluación de síntomas motores categorizando la enfermedad en escalas como Hoehn & Yahr (H&Y). La *Modified Bradykinesia Rating Scale* (MBRS) es una escala alternativa que cuantifica la lentitud en el movimiento a través de la ejecución de tareas motoras estandarizadas, como movimientos repetitivos de dedos, manos y brazos. Esta escala comprende valores entre 0 y 12, siendo los valores altos indicadores de un mayor daño cognitivo. Estas mediciones se correlacionan con el grado de daño neurológico, permitiendo análisis más sensibles y objetivos de la progresión motora de la enfermedad.<br>\n",
    "La valoración de MBRS se da asi:</font>\n",
    "\n",
    "$$\n",
    "MBRS =\n",
    "\\begin{cases}\n",
    "\\text{Low}, & \\text{si } 0 < score \\leq 4 \\\\[6pt]\n",
    "\\text{Medium}, & \\text{si } 4 < \\text{score} \\leq 8 \\\\[6pt]\n",
    "\\text{High}, & \\text{si } 8 < \\text{score} \\leq 12  \\\\[6pt]\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<font size=\"1\">\n",
    "donde (`score`) se obtiene por la suma de cada uno de los valores de las columnas de un dataset, donde cada una de ellas puede tomar valores entre 0 y 4. De este modo, para valores de 3, 2, 4, el MBRS asociado seria alto (valor 9 en la escala).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1757516669665,
     "user": {
      "displayName": "jean carlos portilla",
      "userId": "02695729185455730734"
     },
     "user_tz": 300
    },
    "id": "doI_jnSiHcW7"
   },
   "outputs": [],
   "source": [
    "#@title **code student**\n",
    "\n",
    "def mbrs_rolling(df):\n",
    "\timport pandas as pd\n",
    "\n",
    "\tdfw = df.copy()\n",
    "\tdfw[\"MBRS_smooth\"] = dfw[\"MBRS_score\"].rolling(3).mean()\n",
    "\tdf1 = dfw[[\"MBRS_score\", \"HYY_score\",\"MBRS_smooth\"]]\n",
    "\n",
    "\tdf2 = dfw[\"HYY_score\"].rolling(2).std()\n",
    "\n",
    "\tdf3 = dfw[\"MBRS_score\"].rolling(3).corr(dfw[\"HYY_score\"])\n",
    "\n",
    "\treturn df1, df2, df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Sf546N_MHmXO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MBRS_score  HYY_score  MBRS_smooth\n",
      "0           2          5          NaN\n",
      "1           3          5          NaN\n",
      "2           4          4     3.000000\n",
      "3           5          5     4.000000\n",
      "4           3          5     4.000000\n",
      "5           2          3     3.333333\n",
      "6           4          5     3.000000 \n",
      "\n",
      "0         NaN\n",
      "1    0.000000\n",
      "2    0.707107\n",
      "3    0.707107\n",
      "4    0.000000\n",
      "5    1.414214\n",
      "6    1.414214\n",
      "Name: HYY_score, dtype: float64 \n",
      "\n",
      "0         NaN\n",
      "1         NaN\n",
      "2   -0.866025\n",
      "3    0.000000\n",
      "4    0.000000\n",
      "5    0.755929\n",
      "6    0.866025\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#@title **check your answer**\n",
    "import pandas as pd\n",
    "data = {\"MBRS_score\": [2, 3, 4, 5, 3, 2, 4], \"HYY_score\": [5, 5, 4, 5, 5, 3, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "a, b, c = mbrs_rolling(df)\n",
    "print(a, \"\\n\")\n",
    "print(b, \"\\n\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ksuR4oS47F1"
   },
   "source": [
    "## ✅ Salidas esperadas\n",
    "\n",
    "```\n",
    "   MBRS_score  HYY_score  MBRS_smooth\n",
    "0           2          5          NaN\n",
    "1           3          5          NaN\n",
    "2           4          4     3.000000\n",
    "3           5          5     4.000000\n",
    "4           3          5     4.000000\n",
    "5           2          3     3.333333\n",
    "6           4          5     3.000000\n",
    "\n",
    "0         NaN\n",
    "1    0.000000\n",
    "2    0.707107\n",
    "3    0.707107\n",
    "4    0.000000\n",
    "5    1.414214\n",
    "6    1.414214\n",
    "Name: HYY_score, dtype: float64\n",
    "\n",
    "0         NaN\n",
    "1         NaN\n",
    "2   -0.866025\n",
    "3    0.000000\n",
    "4    0.000000\n",
    "5    0.755929\n",
    "6    0.866025\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "nnhpEceg8qiT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "\t5.0\n",
      "Message\n",
      "\tExcellent, you got the highest score.\n",
      "Status\n",
      "\tYou have achieved your best score: 5.0\n"
     ]
    }
   ],
   "source": [
    "#@title **send your answer**\n",
    "student_func_str = inspect.getsource(mbrs_rolling)\n",
    "r = check_solution_and_evaluate(assignment_id, student_func_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tybUB3zwLJOA"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWUAscibLBc9"
   },
   "source": [
    "---\n",
    "<img src=\"https://gitlab.com/bivl2ab/academico/cursos-uis/ai/ai-uis-student/raw/master/imgs/bannerThanks.jpg\" alt=\"Drawing\" style=\"width:700px;\"/>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
